{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 7: Convolutional Neural Networks.**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), School of Engineering and Applied Science, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Video Material\n",
    "\n",
    "Main video lecture:\n",
    "\n",
    "* [Part 7.1: Data Sets for Computer Vision](https://www.youtube.com/watch?v=u8xn393mDPM&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN&index=21)\n",
    "* [Part 7.2: Convolution Neural Network](https://www.youtube.com/watch?v=cf6FDLFNWEk&index=22&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN)\n",
    "* [Part 7.3: Using Convolutional Neural Networks (CNNs) in Keras and TensorFlow](https://www.youtube.com/watch?v=LSSH_NdXwhU&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN&index=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions\n",
    "\n",
    "You will see these at the top of every module.  These are simply a set of reusable functions that we will make use of.  Each of them will be explained as the semester progresses.  They are explained in greater detail as the course progresses.  Class 4 contains a complete overview of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = f\"{name}-{tv}\"\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m:>02}:{s:>05.2f}\"\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean())\n",
    "                          >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - Pandas dataframe output.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
    "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code == 200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Computer Vision\n",
    "\n",
    "This class will focus on computer vision.  There are some important differences and similarities with previous neural networks.\n",
    "\n",
    "* We will usually use classification, though regression is still an option.\n",
    "* The input to the neural network is now 3D (height, width, color)\n",
    "* Data are not transformed, no z-scores or dummy variables.\n",
    "* Processing time is much longer.\n",
    "* We now have different layer times: dense layers (just like before), convolution layers and max pooling layers.\n",
    "* Data will no longer arrive as CSV files. TensorFlow provides some utilities for going directly from image to the input for a neural network.\n",
    "\n",
    "\n",
    "# Computer Vision Data Sets\n",
    "\n",
    "There are many data sets for computer vision.  Two of the most popular are the MNIST digits data set and the CIFAR image data sets.\n",
    "\n",
    "## MNIST Digits Data Set\n",
    "\n",
    "The [MNIST Digits Data Set](http://yann.lecun.com/exdb/mnist/) is very popular in the neural network research community.  A sample of it can be seen here:\n",
    "\n",
    "![MNIST Data Set](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_8_mnist.png \"MNIST Data Set\")\n",
    "\n",
    "This data set was generated from scanned forms.\n",
    "\n",
    "![Exam](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_8_exam.png \"Exam\")\n",
    "\n",
    "\n",
    "## CIFAR Data Set\n",
    "\n",
    "The [CIFAR-10 and CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) datasets are also frequently used by the neural network research community.\n",
    "\n",
    "![cifar-10](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_8_cifar.png \"cifar-10\")\n",
    "\n",
    "The CIFAR-10 data set contains low-rez images that are divided into 10 classes.  The CIFAR-100 data set contains 100 classes in a hierarchy. \n",
    "\n",
    "# Other Resources\n",
    "\n",
    "* [Imagenet:Large Scale Visual Recognition Challenge 2014](http://image-net.org/challenges/LSVRC/2014/index)\n",
    "* [Andrej Karpathy](http://cs.stanford.edu/people/karpathy/) - PhD student/instructor at Stanford.\n",
    "    * [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/) - Stanford course on computer vision/CNN's.\n",
    "        * [CS231n - GitHub](http://cs231n.github.io/)\n",
    "    * [ConvNetJS](http://cs.stanford.edu/people/karpathy/convnetjs/) - JavaScript library for deep learning.\n",
    " \n",
    "\n",
    "# Convolutional Neural Networks (CNNs)\n",
    "\n",
    "The convolutional neural network (CNN) is a neural network technology that has profoundly impacted the area of computer vision (CV). Fukushima (1980) introduced the original concept of a convolutional neural network, and LeCun, Bottou, Bengio & Haffner (1998) greatly improved this work. From this research, Yan LeCun introduced the famous LeNet-5 neural network architecture. This class follows the LeNet-5 style of convolutional neural network.\n",
    "\n",
    "**A LeNET-5 Network (LeCun, 1998)**\n",
    "![LENET5](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_8_lenet5.png \"LENET5\")\n",
    "\n",
    "So far we have only seen one layer type (dense layers).  By the end of this course we will have seen:\n",
    "\n",
    "* **Dense Layers** - Fully connected layers.  (introduced previously)\n",
    "* **Convolution Layers** - Used to scan across images. (introduced this class)\n",
    "* **Max Pooling Layers** - Used to downsample images. (introduced this class)\n",
    "* **Dropout Layer** - Used to add regularization. (introduced next class)\n",
    "\n",
    "## Convolution Layers\n",
    "\n",
    "The first layer that we will examine is the convolutional layer. We will begin by looking at the hyper-parameters that you must specify for a convolutional layer in most neural network frameworks that support the CNN:\n",
    "\n",
    "* Number of filters\n",
    "* Filter Size\n",
    "* Stride\n",
    "* Padding\n",
    "* Activation Function/Non-Linearity\n",
    "\n",
    "The primary purpose for a convolutional layer is to detect features such as edges, lines, blobs of color, and other visual elements. The filters can detect these features. The more filters that we give to a convolutional layer, the more features it can detect.\n",
    "\n",
    "A filter is a square-shaped object that scans over the image. A grid can represent the individual pixels of a grid. You can think of the convolutional layer as a smaller grid that sweeps left to right over each row of the image. There is also a hyper parameter that specifies both the width and height of the square-shaped filter. Figure 10.1 shows this configuration in which you see the six convolutional filters sweeping over the image grid:\n",
    "\n",
    "A convolutional layer has weights between it and the previous layer or image grid. Each pixel on each convolutional layer is a weight. Therefore, the number of weights between a convolutional layer and its predecessor layer or image field is the following:\n",
    "\n",
    "```\n",
    "[FilterSize] * [FilterSize] * [# of Filters]\n",
    "```\n",
    "\n",
    "For example, if the filter size were 5 (5x4) for 10 filters, there would be 250 weights.\n",
    "\n",
    "You need to understand how the convolutional filters sweep across the previous layer’s output or image grid. Figure 10.2 illustrates the sweep:\n",
    "\n",
    "![CNN](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_8_cnn_grid.png \"CNN\")\n",
    "\n",
    "The above figure shows a convolutional filter with a size of 4 and a padding size of 1. The padding size is responsible for the boarder of zeros in the area that the filter sweeps. Even though the image is actually 8x7, the extra padding provides a virtual image size of 9x8 for the filter to sweep across. The stride specifies the number of positions at which the convolutional filters will stop. The convolutional filters move to the right, advancing by the number of cells specified in the stride. Once the far right is reached, the convolutional filter moves back to the far left, then it moves down by the stride amount and\n",
    "continues to the right again.\n",
    "\n",
    "Some constraints exist in relation to the size of the stride. Obviously, the stride cannot be 0. The convolutional filter would never move if the stride were set to 0. Furthermore, neither the stride, nor the convolutional filter size can be larger than the previous grid. There are additional constraints on the stride (s), padding (p) and the filter width (f) for an image of width (w). Specifically, the convolutional filter must be able to start at the far left or top boarder, move a certain number of strides, and land on the far right or bottom boarder. The following equation shows the number of steps a convolutional operator\n",
    "must take to cross the image:\n",
    "\n",
    "$ steps = \\frac{w - f + 2p}{s+1} $\n",
    "\n",
    "The number of steps must be an integer. In other words, it cannot have decimal places. The purpose of the padding (p) is to be adjusted to make this equation become an integer value.\n",
    "\n",
    "## Max Pooling Layers\n",
    "\n",
    "Max-pool layers downsample a 3D box to a new one with smaller dimensions. Typically, you can always place a max-pool layer immediately following convolutional layer. The LENET shows the max-pool layer immediately after layers C1 and C3. These max-pool layers progressively decrease the size of the dimensions of the 3D boxes passing through them. This technique can avoid overfitting (Krizhevsky, Sutskever & Hinton, 2012).\n",
    "\n",
    "A pooling layer has the following hyper-parameters:\n",
    "\n",
    "* Spatial Extent (f )\n",
    "* Stride (s)\n",
    "\n",
    "Unlike convolutional layers, max-pool layers do not use padding. Additionally, max-pool layers have no weights, so training does not affect them. These layers simply downsample their 3D box input. The 3D box output by a max-pool layer will have a width equal to this equation:\n",
    "\n",
    "$ w_2 = \\frac{w_1 - f}{s + 1} $\n",
    "\n",
    "The height of the 3D box produced by the max-pool layer is calculated similarly with this equation:\n",
    "\n",
    "$ h_2 = \\frac{h_1 - f}{s + 1} $\n",
    "\n",
    "The depth of the 3D box produced by the max-pool layer is equal to the depth the 3D box received as input. The most common setting for the hyper-parameters of a max-pool layer are f =2 and s=2. The spatial extent (f) specifies that boxes of 2x2 will be scaled down to single pixels. Of these four pixels, the pixel with the maximum value will represent the 2x2 pixel in the new grid. Because squares of size 4 are replaced with size 1, 75% of the pixel information is lost. The following figure shows this transformation as a 6x6 grid becomes a 3x3:\n",
    "\n",
    "![MaxPool](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_8_conv_maxpool.png \"MaxPool\")\n",
    "\n",
    "Of course, the above diagram shows each pixel as a single number. A grayscale image would have this characteristic. For an RGB image, we usually take the average of the three numbers to determine which pixel has the maximum value.\n",
    "\n",
    "[More information on CNN's](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "# TensorFlow with CNNs\n",
    "\n",
    "The following sections describe how to use TensorFlow/Keras with CNNs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access to Data Sets\n",
    "\n",
    "Keras provides built in access classes for MNIST.  It is important to note that MNIST data arrives already separated into two sets:\n",
    "\n",
    "* **train** - Neural network will be trained with this.\n",
    "* **test** - Used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mriga\\.keras\\datasets\\kddcup.data_10_percent.gz\n",
      "Read 494021 rows.\n",
      "Shape of x_train: (370515, 120)\n",
      "Shape of y_train: (370515, 23)\n",
      "\n",
      "Shape of x_test: (123506, 120)\n",
      "Shape of y_test: (123506, 23)\n",
      "Shape for single: (120,)\n",
      "Shape for single label: (23,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.067792</td>\n",
       "      <td>-0.002535</td>\n",
       "      <td>-0.026287</td>\n",
       "      <td>-0.047720</td>\n",
       "      <td>-0.002571</td>\n",
       "      <td>-0.044136</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.005679</td>\n",
       "      <td>-0.010552</td>\n",
       "      <td>-0.004676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005640</td>\n",
       "      <td>-0.011232</td>\n",
       "      <td>-0.009919</td>\n",
       "      <td>-0.027632</td>\n",
       "      <td>0.838454</td>\n",
       "      <td>0.885397</td>\n",
       "      <td>-0.464089</td>\n",
       "      <td>-0.463520</td>\n",
       "      <td>-0.247960</td>\n",
       "      <td>-0.248631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536987</td>\n",
       "      <td>-0.255243</td>\n",
       "      <td>-0.203633</td>\n",
       "      <td>0.347966</td>\n",
       "      <td>0.625557</td>\n",
       "      <td>0.599396</td>\n",
       "      <td>-0.282866</td>\n",
       "      <td>0.827047</td>\n",
       "      <td>-0.158629</td>\n",
       "      <td>-0.464417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.463202</td>\n",
       "      <td>-0.252039</td>\n",
       "      <td>-0.249464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -0.067792 -0.002535 -0.026287 -0.047720 -0.002571 -0.044136 -0.009782   \n",
       "1  -0.005640 -0.011232 -0.009919 -0.027632  0.838454  0.885397 -0.464089   \n",
       "2   0.536987 -0.255243 -0.203633  0.347966  0.625557  0.599396 -0.282866   \n",
       "3  -0.463202 -0.252039 -0.249464  1.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  1.000000  0.000000  1.000000  0.000000  1.000000  0.000000   \n",
       "\n",
       "           7         8         9  \n",
       "0  -0.005679 -0.010552 -0.004676  \n",
       "1  -0.463520 -0.247960 -0.248631  \n",
       "2   0.827047 -0.158629 -0.464417  \n",
       "3   0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  \n",
       "10  0.000000  0.000000  0.000000  \n",
       "11  1.000000  1.000000  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape after float 32: (370515, 12, 10, 1)\n",
      "Training samples: 370515\n",
      "Test samples: 123506\n",
      "Before astype('flot32')\n",
      "\n",
      "New Test samples label shape: 123506\n",
      "New y_train shape: (370515, 23)\n",
      "New y_test shape: (123506, 23)\n",
      "After astype('flot32')\n",
      "\n",
      "New Test samples label shape: 123506\n",
      "New y_train shape: (370515, 23)\n",
      "New y_test shape: (123506, 23)\n",
      "After to_categorical\n",
      "\n",
      "New Test samples label shape: 123506\n",
      "New y_train shape: (370515, 23)\n",
      "New y_test shape: (123506, 23)\n",
      "\n",
      " New Test samples x_train shape: 123506\n",
      "New x_train shape: (370515, 12, 10, 1)\n",
      "New x_test shape: (123506, 12, 10, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 9, 7, 32)          544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 1, 32)          9248      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 23)                2967      \n",
      "=================================================================\n",
      "Total params: 21,079\n",
      "Trainable params: 21,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "#from keras.datasets import mnist\n",
    "from keras.utils.data_utils import get_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    path = get_file('kddcup.data_10_percent.gz', origin='http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz')\n",
    "except:\n",
    "    print('Error downloading')\n",
    "    raise\n",
    "    \n",
    "print(path) \n",
    "\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "# Download from: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "df = pd.read_csv(path, header=None)\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "df.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]\n",
    "\n",
    "# display 5 rows\n",
    "df[0:5]\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------#\n",
    "\n",
    "encode_numeric_zscore(df, 'duration')\n",
    "encode_text_dummy(df, 'protocol_type')\n",
    "encode_text_dummy(df, 'service')\n",
    "encode_text_dummy(df, 'flag')\n",
    "encode_numeric_zscore(df, 'src_bytes')\n",
    "encode_numeric_zscore(df, 'dst_bytes')\n",
    "encode_text_dummy(df, 'land')\n",
    "encode_numeric_zscore(df, 'wrong_fragment')\n",
    "encode_numeric_zscore(df, 'urgent')\n",
    "encode_numeric_zscore(df, 'hot')\n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "encode_text_dummy(df, 'logged_in')\n",
    "encode_numeric_zscore(df, 'num_compromised')\n",
    "encode_numeric_zscore(df, 'root_shell')\n",
    "encode_numeric_zscore(df, 'su_attempted')\n",
    "encode_numeric_zscore(df, 'num_root')\n",
    "encode_numeric_zscore(df, 'num_file_creations')\n",
    "encode_numeric_zscore(df, 'num_shells')\n",
    "encode_numeric_zscore(df, 'num_access_files')\n",
    "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
    "encode_text_dummy(df, 'is_host_login')\n",
    "encode_text_dummy(df, 'is_guest_login')\n",
    "encode_numeric_zscore(df, 'count')\n",
    "encode_numeric_zscore(df, 'srv_count')\n",
    "encode_numeric_zscore(df, 'serror_rate')\n",
    "encode_numeric_zscore(df, 'srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'rerror_rate')\n",
    "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
    "encode_numeric_zscore(df, 'same_srv_rate')\n",
    "encode_numeric_zscore(df, 'diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_count')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
    "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
    "outcomes = encode_text_index(df, 'outcome')\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "df.dropna(inplace=True,axis=1)\n",
    "\n",
    "df[0:5]\n",
    "# This is the numeric feature vector, as it goes to the neural net\n",
    "\n",
    "#---------------------------------------------------#\n",
    "\n",
    "# Break into X (predictors) & y (prediction)\n",
    "x, y = to_xy(df,'outcome')\n",
    "\n",
    "# Create a test/train split.  25% test\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print()\n",
    "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))\n",
    "\n",
    "single = x_train[0]\n",
    "print(\"Shape for single: {}\".format(single.shape))\n",
    "\n",
    "single_label = y_train[0]\n",
    "print(\"Shape for single label: {}\".format(single_label.shape))\n",
    "\n",
    "display(pd.DataFrame(single.reshape(12,10)))\n",
    "df[0:5]\n",
    "\n",
    "\n",
    "#----------------------------------CNN Model---------------------------------------------#\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 8\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 12, 10\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#-------------------Print Statements----------------------------------------#\n",
    "\n",
    "print('x_train shape after float 32:', x_train.shape)\n",
    "print(\"Training samples: {}\".format(x_train.shape[0]))\n",
    "print(\"Test samples: {}\".format(x_test.shape[0]))\n",
    "\n",
    "print(\"Before astype('flot32')\\n\")\n",
    "\n",
    "print(\"New Test samples label shape: {}\".format(y_test.shape[0]))\n",
    "print('New y_train shape:', y_train.shape)\n",
    "print('New y_test shape:', y_test.shape)\n",
    "\n",
    "print(\"After astype('flot32')\\n\")\n",
    "\n",
    "y_train = (y_train == 1).astype('float32')\n",
    "#y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "y_test = (y_test == 1).astype('float32')\n",
    "#y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"New Test samples label shape: {}\".format(y_test.shape[0]))\n",
    "print('New y_train shape:', y_train.shape)\n",
    "print('New y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"After to_categorical\\n\")\n",
    "\n",
    "\n",
    "print(\"New Test samples label shape: {}\".format(y_test.shape[0]))\n",
    "print('New y_train shape:', y_train.shape)\n",
    "print('New y_test shape:', y_test.shape)\n",
    "\n",
    "print(\"\\n New Test samples x_train shape: {}\".format(x_test.shape[0]))\n",
    "print('New x_train shape:', x_train.shape)\n",
    "print('New x_test shape:', x_test.shape)\n",
    "\n",
    "\n",
    "#-------------------------------------CNN Model Continues---------------------------#\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(4, 4),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "#model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "#model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.add(Dense(23, activation='softmax'))\n",
    "\n",
    "#model.add(Dense(23, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#for i in x_train:\n",
    "#    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the Digits \n",
    "\n",
    "The following code shows what the MNIST files contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Fitting CNN\n",
    "\n",
    "The following code will train the CNN for 20,000 steps.  This can take awhile, you might want to scale the step count back. GPU training can help.  My results:\n",
    "\n",
    "* CPU Training Time: Elapsed time: 1:50:13.10\n",
    "* GPU Training Time: Elapsed time: 0:13:43.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 370515 samples, validate on 123506 samples\n",
      "Epoch 1/8\n",
      " - 22s - loss: 0.5913 - acc: 0.7831 - val_loss: 0.0724 - val_acc: 0.9807\n",
      "Epoch 2/8\n",
      " - 21s - loss: 0.0657 - acc: 0.9836 - val_loss: 0.0409 - val_acc: 0.9881\n",
      "Epoch 3/8\n",
      " - 23s - loss: 0.0422 - acc: 0.9891 - val_loss: 0.0267 - val_acc: 0.9924\n",
      "Epoch 4/8\n",
      " - 21s - loss: 0.0316 - acc: 0.9921 - val_loss: 0.0221 - val_acc: 0.9938\n",
      "Epoch 5/8\n",
      " - 21s - loss: 0.0263 - acc: 0.9936 - val_loss: 0.0173 - val_acc: 0.9960\n",
      "Epoch 6/8\n",
      " - 22s - loss: 0.0222 - acc: 0.9948 - val_loss: 0.0153 - val_acc: 0.9963\n",
      "Epoch 7/8\n",
      " - 21s - loss: 0.0197 - acc: 0.9954 - val_loss: 0.0140 - val_acc: 0.9971\n",
      "Epoch 8/8\n",
      " - 22s - loss: 0.0181 - acc: 0.9958 - val_loss: 0.0128 - val_acc: 0.9973\n",
      "Test loss: 0.012784965354586142\n",
      "Test accuracy: 0.9972713876248928\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:03:01.14\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}'.format(score[0]))\n",
    "print('Test accuracy: {}'.format(score[1]))\n",
    "\n",
    "#------------Predictions------------------------------------#\n",
    "\n",
    "predictions = model.predict(x_test, batch_size, verbose=0)\n",
    "\n",
    "#for i in predictions:\n",
    "#    print(i)\n",
    "\n",
    "#------------Predictions End--------------------------------#\n",
    "\n",
    "#----------------------Confusion Matrix-------------------------------------#\n",
    "\n",
    "\n",
    "labels = ['business', 'health']\n",
    "#cm = confusion_matrix(y_test, pred, labels)\n",
    "#cm = confusion_matrix([1,2,3,4,5,0,1], [1,2,3,4,5,1,0], labels)\n",
    "cm = confusion_matrix([1,2,3,4,5,0,1], [1,2,3,4,5,1,0])\n",
    "#cm = confusion_matrix(rounded_predictions, rounded_predictions)\n",
    "#print(cm)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "#-----------------------COnfusion Matrix Ends------------------------------------#\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy\n",
    "\n",
    "Note, if you are using a GPU you might get the **ResourceExhaustedError**.  This occurs because the GPU might not have enough ram to predict the entire data set at once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.012784965354586142\n",
      "Test accuracy: 0.9972713876248928\n"
     ]
    }
   ],
   "source": [
    "# Predict using either GPU or CPU, send the entire dataset.  This might not work on the GPU.\n",
    "# Set the desired TensorFlow output level for this example\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}'.format(score[0]))\n",
    "print('Test accuracy: {}'.format(score[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs are most often used for training rather than prediction.  For prediction either disable the GPU or just predict on a smaller sample.  If your GPU has enough memory, the above prediction code may work just fine.  If not, just prediction on a sample with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# For GPU just grab the first 100 images\n",
    "small_x = x_test[1:100]\n",
    "small_y = y_test[1:100]\n",
    "small_y2 = np.argmax(small_y,axis=1)\n",
    "pred = model.predict(small_x)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "score = metrics.accuracy_score(small_y2, pred)\n",
    "print('Accuracy: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Latest Advances in CNN's\n",
    "\n",
    "He, K., Zhang, X., Ren, S., & Sun, J. (2016). [Deep residual learning for image recognition](https://arxiv.org/abs/1512.03385). In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition* (pp. 770-778).\n",
    "\n",
    "* [Caffee ResNet GitHub](https://github.com/KaimingHe/deep-residual-networks)\n",
    "* [ResNet in TensorFlow](https://github.com/tensorflow/models/blob/master/resnet/resnet_model.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Geoffrey Hinton is suggesting that we might be [doing computer vision wrong](https://www.wired.com/story/googles-ai-wizard-unveils-a-new-twist-on-neural-networks/) and has introduced two new papers about an old technique called Capsule Neural Networks:\n",
    "    \n",
    "* Sabour, S., Frosst, N., & Hinton, G. E. (2017). [Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829). arXiv preprint arXiv:1710.09829.\n",
    "* [Matrix capsules with EM routing](https://openreview.net/forum?id=HJWLfGWRb&noteId=HJWLfGWRb) - ICLR 2018 Blind Submission\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Module 7 Assignment\n",
    "\n",
    "You can find the first assignment here: [assignment 7](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class7.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
